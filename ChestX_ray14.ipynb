{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PjJyffCD-mz",
    "outputId": "4eedc567-4afa-4632-9edc-db3250be7b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading/content/drive/MyDrive/ChestX-ray14/images_01.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_02.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_03.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_04.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_05.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_06.tar.gz...\n",
      "downloading/content/drive/MyDrive/ChestX-ray14/images_07.tar.gz...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# Download the 56 zip files in Images_png in batches\n",
    "import urllib.request\n",
    "\n",
    "# URLs for the zip files\n",
    "links = [\n",
    "    'https://nihcc.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.gz',\n",
    "    'https://nihcc.box.com/shared/static/i28rlmbvmfjbl8p2n3ril0pptcmcu9d1.gz',\n",
    "    'https://nihcc.box.com/shared/static/f1t00wrtdk94satdfb9olcolqx20z2jp.gz',\n",
    "\t'https://nihcc.box.com/shared/static/0aowwzs5lhjrceb3qp67ahp0rd1l1etg.gz',\n",
    "    'https://nihcc.box.com/shared/static/v5e3goj22zr6h8tzualxfsqlqaygfbsn.gz',\n",
    "\t'https://nihcc.box.com/shared/static/asi7ikud9jwnkrnkj99jnpfkjdes7l6l.gz',\n",
    "\t'https://nihcc.box.com/shared/static/jn1b4mw4n6lnh74ovmcjb8y48h8xj07n.gz',\n",
    "    'https://nihcc.box.com/shared/static/tvpxmn7qyrgl0w8wfh9kqfjskv6nmm1j.gz',\n",
    "\t'https://nihcc.box.com/shared/static/upyy3ml7qdumlgk2rfcvlb9k6gvqq2pj.gz',\n",
    "\t'https://nihcc.box.com/shared/static/l6nilvfa9cg3s28tqv1qc1olm3gnz54p.gz',\n",
    "\t'https://nihcc.box.com/shared/static/hhq8fkdgvcari67vfhs7ppg2w6ni4jze.gz',\n",
    "\t'https://nihcc.box.com/shared/static/ioqwiy20ihqwyr8pf4c24eazhh281pbu.gz'\n",
    "]\n",
    "\n",
    "for idx, link in enumerate(links):\n",
    "    base_path = './ChestX-ray14/'\n",
    "  # fullfilename = os.path.join(myPath, filename)\n",
    "    fn = base_path + 'images_%02d.tar.gz' % (idx+1)\n",
    "    print('downloading ' +fn+'...')\n",
    "    urllib.request.urlretrieve(link, fn)  # download the zip file\n",
    "\n",
    "print(\"Download complete. Please check the checksums\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGt-7EzzETwq"
   },
   "outputs": [],
   "source": [
    "! pwd\n",
    "! ls -l /content/drive/MyDrive/ChestX-ray14/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abhvK0Pl0o_M",
    "outputId": "42f3d4d1-4d61-4679-d254-14d3ce6a8fae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   25000\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l ./ChestX-ray14/images/images/ |wc -l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_dkRlb3XtnnJ"
   },
   "outputs": [],
   "source": [
    "! ls -l /content/drive/MyDrive/ChestX-ray14/images/ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zlusz6BuWJz-",
    "outputId": "1d78ff6c-0629-4290-ee61-a03a3d87cb72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '/content/images/*.png': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! mv -n  /content/images/*.png /content/drive/MyDrive/ChestX-ray14/images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uX-l5C94WSgn"
   },
   "outputs": [],
   "source": [
    "! ls -l /content/drive/MyDrive/ChestX-ray14/images/ |wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "7AQ5tDpCCyrM"
   },
   "outputs": [],
   "source": [
    "# encoding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Read images and corresponding labels.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "class ChestXrayDataSet(Dataset):\n",
    "    def __init__(self, data_dir, image_list_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir: path to image directory.\n",
    "            image_list_file: path to the file containing images\n",
    "                with corresponding labels.\n",
    "            transform: optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        image_names = []\n",
    "        labels = []\n",
    "        with open(image_list_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                items = line.split()\n",
    "                image_name= items[0]\n",
    "                label = items[1:]\n",
    "                label = [int(i) for i in label]\n",
    "                image_name = os.path.join(data_dir, image_name)\n",
    "                image_names.append(image_name)\n",
    "                labels.append(label)\n",
    "\n",
    "        self.image_names = image_names\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index: the index of item\n",
    "\n",
    "        Returns:\n",
    "            image and its labels\n",
    "        \"\"\"\n",
    "        image_name = self.image_names[index]\n",
    "        image = Image.open(image_name).convert('RGB')\n",
    "        label = self.labels[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "xcXFGJ0bP4Ak"
   },
   "outputs": [],
   "source": [
    "def compute_AUCs(gt, pred):\n",
    "    \"\"\"Computes Area Under the Curve (AUC) from prediction scores.\n",
    "\n",
    "    Args:\n",
    "        gt: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          true binary labels.\n",
    "        pred: Pytorch tensor on GPU, shape = [n_samples, n_classes]\n",
    "          can either be probability estimates of the positive class,\n",
    "          confidence values, or binary decisions.\n",
    "\n",
    "    Returns:\n",
    "        List of AUROCs of all classes.\n",
    "    \"\"\"\n",
    "    AUROCs = []\n",
    "    gt_np = gt.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    for i in range(N_CLASSES):\n",
    "        AUROCs.append(roc_auc_score(gt_np[:, i], pred_np[:, i]))\n",
    "    return AUROCs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7tsSl6VUP4V4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class DenseNet121(nn.Module):\n",
    "    \"\"\"Model modified.\n",
    "\n",
    "    The architecture of our model is the same as standard DenseNet121\n",
    "    except the classifier layer which has an additional sigmoid function.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, out_size):\n",
    "        super(DenseNet121, self).__init__()\n",
    "        self.densenet121 = torchvision.models.densenet121(pretrained=True)\n",
    "        num_ftrs = self.densenet121.classifier.in_features\n",
    "        self.densenet121.classifier = nn.Sequential(\n",
    "            nn.Linear(num_ftrs, out_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.densenet121(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 713
    },
    "id": "BFPwp8GpCwk3",
    "outputId": "ae9b6cde-c399-4f86-dc7b-5dfec2b89249"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arikpeled/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/arikpeled/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DenseNet121' object has no attribute 'metal'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 82\u001B[0m\n\u001B[1;32m     75\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe AUROC of \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m is \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(CLASS_NAMES[i], AUROCs[i]))\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 82\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 26\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# initialize and load the model\u001B[39;00m\n\u001B[1;32m     25\u001B[0m model \u001B[38;5;241m=\u001B[39m DenseNet121(N_CLASSES)\n\u001B[0;32m---> 26\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetal\u001B[49m()\n\u001B[1;32m     27\u001B[0m model \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mDataParallel(model)\n\u001B[1;32m     28\u001B[0m model\u001B[38;5;241m.\u001B[39mmodule \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mmodule\u001B[38;5;241m.\u001B[39mmetal()\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[1;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[0;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'DenseNet121' object has no attribute 'metal'"
     ]
    }
   ],
   "source": [
    "# encoding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "The main CheXNet model implementation.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "CKPT_PATH = 'model.pth.tar'\n",
    "N_CLASSES = 14\n",
    "CLASS_NAMES = [ 'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', 'Pneumonia',\n",
    "                'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n",
    "DATA_DIR = './ChestX-ray14/images'\n",
    "TEST_IMAGE_LIST = '/content/drive/MyDrive/ChestX-ray14/labels/test_list.txt'\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # initialize and load the model\n",
    "    model = DenseNet121(N_CLASSES)\n",
    "    model = model.metal()\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.module = model.module.metal()\n",
    "    if os.path.isfile(CKPT_PATH):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        checkpoint = torch.load(CKPT_PATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\"=> loaded checkpoint\")\n",
    "    else:\n",
    "        print(\"=> no checkpoint found\")\n",
    "\n",
    "    normalize = transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                     [0.229, 0.224, 0.225])\n",
    "\n",
    "    test_dataset = ChestXrayDataSet(data_dir=DATA_DIR,\n",
    "                                    image_list_file=TEST_IMAGE_LIST,\n",
    "                                    transform=transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.TenCrop(224),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "                                        transforms.Lambda\n",
    "                                        (lambda crops: torch.stack([normalize(crop) for crop in crops]))\n",
    "                                    ]))\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,\n",
    "                             shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "    # initialize the ground truth and output tensor\n",
    "    gt = torch.FloatTensor()\n",
    "    gt = gt.metal()\n",
    "    pred = torch.FloatTensor()\n",
    "    pred = pred.metal()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inp, target) in enumerate(test_loader):\n",
    "        target = target.cuda()\n",
    "        gt = torch.cat((gt, target), 0)\n",
    "        bs, n_crops, c, h, w = inp.size()\n",
    "        input_var = torch.autograd.Variable(inp.view(-1, c, h, w).metal(), volatile=True)\n",
    "        output = model(input_var)\n",
    "        output_mean = output.view(bs, n_crops, -1).mean(1)\n",
    "        pred = torch.cat((pred, output_mean.data), 0)\n",
    "\n",
    "    AUROCs = compute_AUCs(gt, pred)\n",
    "    AUROC_avg = np.array(AUROCs).mean()\n",
    "    print('The average AUROC is {AUROC_avg:.3f}'.format(AUROC_avg=AUROC_avg))\n",
    "    for i in range(N_CLASSES):\n",
    "        print('The AUROC of {} is {}'.format(CLASS_NAMES[i], AUROCs[i]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "q377Hj6U0mnD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/9t/wzkngdzn78n84hdt1d1g29tc0000gn/T/ipykernel_64057/897549616.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 08:58:38.391310: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-24 08:58:38.391793: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False, min_cuda_compute_capability=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
